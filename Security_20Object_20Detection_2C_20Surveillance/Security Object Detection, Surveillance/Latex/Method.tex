\section{Method}

Security surveillance  is very important in the present time because there tends to be a lot of theft. Leaving people unsteady when it comes to the holidays and every other day. This also comes useful in companies like construction that require constant surveillance to make sure their workers are doing what they should be doing. The problem is to implement a design representing computer vision that allows detecting images live for safety purposes. As explained above there are numerous ways that a Raspberry Pi can be used to create a live image detector. We go forward with using a Raspberry Pi because it allows us to code the algorithm in Linux using python, it also has enough memory and a fast enough processor to detect at least 4 frames per second. It is not as clear since we must stay under budget. Implementing a graphics card like Nvidia, commonly used in PCs, for better graphics, or a 12 MP camera, for clearer pictures would not benefit the project since we are trying to stay under budget. Thus, Raspberry Pi, Linux, a budgeted camera, python, and the required files will have to do. The fact it works allows us to test further research along the way staying under budget and saving money.

TensorFlow Lite was used with COCO, a program installed with over a thousand detected images developed by Google, making the algorithm easier to read the live detection we plan to test. The frames per second aren’t planned to be high enough but that is fair based on the board and camera used. There are many boards researched to use, but raspberry pi was the most convenient since it has the camera that works with it, the memory stands enough, and it works with the free open-source operating system Linux. We aren’t expecting it to work ideally with a higher resolution or frames per second, but it allows it to detect an image with at least 60 percent accuracy and an estimate of 70 to 80 percent accuracy.

Libraries used in the python algorithm consist of a few like numpy, tflite, and cv2. The coded algorithm defines a video stream class that handles the streaming of the video from the installed USB webcam, or a Picamera. The code will loop indefinitely with a thread that reads the frames per second until the program is stopped. The TensorFlow libraries will then be used to calculate the runtime, and a load\_delehgate library is imported if a Coral Edge TPU is to be used. Once the timer starts, a frame is captured and resized ideally (1xHxWx3), to normalize the pixels in the image that allows the algorithm to perform the actual detection and retrieve the results. Which then will be recorded in another file for further analysis and experimentation.

Furthermore, this experiment can be tested multiple times as the budget increases, and different programs are embedded to allow for a cleaner, faster, and more efficient image detector. Adding additional software and libraries that can help the detection boxes, like the technique Non-Maximum Suppression can be something to advance the computer vision research and test for better working security surveillance that allows for faster detection with higher accuracy. This was used in one of the mentioned tutorials, which is beneficial for us to have because this technique is of interest to implement and embed in the raspberry pi.

The other tutorial also was useful for the COCO file from TensorFlow, developed by Google. This was used to search for data to help identify the object detected on the live camera embedded onto the raspberry pi.

